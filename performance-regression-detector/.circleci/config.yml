version: 2.1

orbs:
  node: circleci/node@5.1.0

# ============================================================
# PERFORMANCE REGRESSION DETECTOR
# Demonstrates Kubiya Cognitive Memory for baseline tracking
# and automatic regression detection
# ============================================================

# Environment variables for memory datasets (set in CircleCI context or project settings)
# KUBIYA_DATASET_BASELINES - Dataset for performance baselines (default: "default")
# KUBIYA_DATASET_BENCHMARK_RUNS - Dataset for benchmark runs (default: "default")
# KUBIYA_DATASET_ALERTS - Dataset for performance alerts (default: "default")
# KUBIYA_DATASET_TRENDS - Dataset for performance trends (default: "default")

executors:
  node-executor:
    docker:
      - image: cimg/node:20.11
    working_directory: ~/project
    resource_class: medium
    environment:
      KUBIYA_DATASET_BASELINES: ${KUBIYA_DATASET_BASELINES:-default}
      KUBIYA_DATASET_BENCHMARK_RUNS: ${KUBIYA_DATASET_BENCHMARK_RUNS:-default}
      KUBIYA_DATASET_ALERTS: ${KUBIYA_DATASET_ALERTS:-default}
      KUBIYA_DATASET_TRENDS: ${KUBIYA_DATASET_TRENDS:-default}

commands:
  install-kubiya-cli:
    description: Install Kubiya CLI
    steps:
      - run:
          name: Install Kubiya CLI
          command: |
            curl -fsSL https://raw.githubusercontent.com/kubiyabot/cli/main/install.sh | bash
            echo 'export PATH="$HOME/.kubiya/bin:$PATH"' >> $BASH_ENV
            source $BASH_ENV

  recall-performance-baselines:
    description: Recall performance baselines from memory
    steps:
      - run:
          name: Recall Performance Baselines
          command: |
            echo "=== Recalling Performance Baselines ==="

            # Recall baselines for this repository
            BASELINES=$(kubiya memory recall "performance baselines for ${CIRCLE_PROJECT_REPONAME}" \
              --top-k 10 --output json 2>/dev/null || echo "[]")

            # Recall any known performance issues
            PERF_ISSUES=$(kubiya memory recall "performance issues in ${CIRCLE_PROJECT_REPONAME}" \
              --top-k 5 --output json 2>/dev/null || echo "[]")

            echo "export BASELINES='$BASELINES'" >> $BASH_ENV
            echo "export PERF_ISSUES='$PERF_ISSUES'" >> $BASH_ENV

            echo "Recalled baselines and known issues"

  store-performance-baseline:
    description: Store current performance as baseline
    steps:
      - run:
          name: Store Performance Baseline
          command: |
            kubiya exec "
              You are a performance baseline manager for ${CIRCLE_PROJECT_REPONAME} (build #${CIRCLE_BUILD_NUM}, branch: ${CIRCLE_BRANCH}).

              HISTORICAL BASELINES:
              $BASELINES

              TASK: Update performance baselines

              1. Read benchmark-results.json
              2. Compare to historical baselines

              3. Determine if this run is representative:
                 - Low variance in results
                 - No anomalies or outliers
                 - Consistent with recent trends

              4. If this is a stable, representative run:
                 - Store as new baseline in memory
                 - Include mean, p95, and stdDev for each benchmark

              5. If this run shows anomalies:
                 - Do not update baselines
                 - Report why this run was excluded

              Be selective - only store stable baselines to ensure accuracy.
            " --local --cwd . --yes

jobs:
  # ============================================================
  # BASELINE: Run benchmarks without comparison
  # ============================================================
  benchmark-baseline:
    executor: node-executor
    steps:
      - checkout
      - node/install-packages:
          pkg-manager: npm
      - run:
          name: Run Benchmarks
          command: npm run benchmark:json
      - store_artifacts:
          path: benchmark-results.json

  # ============================================================
  # INTELLIGENT: Run benchmarks with regression detection
  # ============================================================
  benchmark-with-detection:
    executor: node-executor
    steps:
      - checkout
      - node/install-packages:
          pkg-manager: npm
      - install-kubiya-cli

      # Phase 1: Recall baselines
      - recall-performance-baselines

      # Phase 2: Run benchmarks
      - run:
          name: Run Benchmarks
          command: npm run benchmark:json

      # Phase 3: Compare and detect regressions
      - run:
          name: Detect Performance Regressions
          command: |
            kubiya exec "
              HISTORICAL BASELINES:
              $BASELINES

              KNOWN PERFORMANCE ISSUES:
              $PERF_ISSUES

              TASK: Analyze benchmark results for regressions

              1. Read benchmark-results.json

              2. For each benchmark, compare to baseline:
                 - Calculate ratio: current_mean / baseline_mean
                 - If ratio > 1.5: REGRESSION (50% slower)
                 - If ratio > 2.0: CRITICAL REGRESSION
                 - If ratio < 0.8: IMPROVEMENT (20% faster)

              3. Check for known issues:
                 - Are any regressions matching known issues?
                 - Any new patterns not seen before?

              4. Report findings:
                 For each regression:
                 - Benchmark name
                 - Current value vs baseline
                 - Percentage change
                 - Severity (warning/critical)

              5. If CRITICAL regressions found, fail the build
            " --local --cwd . --yes

      # Phase 4: Store results
      - run:
          name: Store Benchmark Results
          command: |
            kubiya exec "
              You are storing benchmark results for ${CIRCLE_PROJECT_REPONAME} (build #${CIRCLE_BUILD_NUM}, branch: ${CIRCLE_BRANCH}).

              TASK: Store benchmark results to memory

              1. Read benchmark-results.json

              2. Store the run record to memory including:
                 - Pass/regression status
                 - List of regressed benchmarks (if any)
                 - List of improved benchmarks (if any)

              3. If regressions were detected:
                 - Store an alert to memory with severity and details
                 - Include which benchmarks regressed and by how much

              This data enables trend analysis across builds.
            " --local --cwd . --yes

      # Phase 5: Update baseline if appropriate
      - store-performance-baseline

      - store_artifacts:
          path: benchmark-results.json

  # ============================================================
  # CLI PATTERN: Direct baseline comparison
  # ============================================================
  cli-baseline-comparison:
    executor: node-executor
    steps:
      - checkout
      - node/install-packages:
          pkg-manager: npm
      - install-kubiya-cli

      - run:
          name: CLI Baseline Pattern
          command: |
            echo "=== CLI Baseline Comparison Pattern ==="

            # Step 1: Recall baseline via CLI
            BASELINE=$(kubiya memory recall "performance baseline for ${CIRCLE_PROJECT_REPONAME} main branch" \
              --top-k 1 --output json 2>/dev/null || echo "{}")

            echo "Baseline: $BASELINE"

            # Step 2: Run benchmarks
            npm run benchmark:json

            # Step 3: Pass both to agent
            kubiya exec "
              PERFORMANCE BASELINE:
              $BASELINE

              CURRENT RESULTS:
              $(cat benchmark-results.json)

              TASK:
              1. Compare each benchmark to baseline
              2. Flag any >50% regressions
              3. Report summary with pass/fail status
              4. If this is a clean run on main, suggest updating baseline
            " --local --cwd . --yes

  # ============================================================
  # TREND ANALYSIS: Long-term performance tracking
  # ============================================================
  performance-trends:
    executor: node-executor
    steps:
      - checkout
      - install-kubiya-cli

      - run:
          name: Analyze Performance Trends
          command: |
            kubiya exec "
              You are a performance trend analyst for ${CIRCLE_PROJECT_REPONAME}.

              TASK: Analyze long-term performance trends

              1. Recall historical benchmark data from memory

              2. For each benchmark, analyze the trend:
                 - Is it getting slower over time?
                 - Is it getting faster?
                 - Is it stable?
                 - What's the variance?

              3. Identify concerning patterns:
                 - Gradual degradation (frog in boiling water)
                 - Sudden jumps
                 - Increased variance (instability)

              4. Store your trend analysis to memory for future reference

              5. If any benchmark shows consistent degradation:
                 - Store an alert to memory
                 - Explain the trend and recommend investigation

              Focus on catching slow degradation that individual runs might miss.
            " --local --cwd . --yes

workflows:
  version: 2

  # Baseline - no comparison
  baseline:
    jobs:
      - benchmark-baseline

  # Full regression detection
  regression-detection:
    jobs:
      - benchmark-with-detection:
          context: kubiya-secrets

  # CLI pattern demo
  cli-pattern:
    jobs:
      - cli-baseline-comparison:
          context: kubiya-secrets

  # Weekly trend analysis
  weekly-trends:
    triggers:
      - schedule:
          cron: "0 0 * * 0"
          filters:
            branches:
              only: main
    jobs:
      - performance-trends:
          context: kubiya-secrets
